{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003a9cd1",
   "metadata": {},
   "source": [
    "# Carregando dados e gerenciar checkpoints\n",
    "- O objetivo deste notebook é aprendermos as seguintes features do PyTorch:\n",
    "    1. Criar datasets customizados que nos permita carregar dados do disco\n",
    "    2. Criar e gerênciar checkpoints do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365574c",
   "metadata": {},
   "source": [
    "## Carregando novos datasets\n",
    "- Até o momento nos carregamos dados usando o `torchvision.datasets`, que basicamente nos retorna uma instância personalizada do `torch.utils.data.Dataset`\n",
    "- Para carregarmos os nossos próprios datasets precisamos criar uma instância desse mesmo objeto\n",
    "- E na sequência, passar esse dataset para um `torch.utils.data.Dataloader`\n",
    "- Então vamos começar com o dataset\n",
    "    - Para criar um dataset customizado, basta estender a classe `torch.utils.data.Dataset`\n",
    "    - E a partir dai, você decise a maneira que deseja carregar os dados seguindo a padronização do framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8783f-a814-47e9-8066-78b3f836c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset (torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Esse dataset recebe uma lista de path de imagens, uma lista de labels correspondentes e (opcional) transformações pata aplicar nas imagens\n",
    "    quando elas forem carregadas\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, imgs_path, labels, my_transform=None):\n",
    "        \"\"\"\n",
    "        imgs_path: list ou tuple\n",
    "            Uma lista ou tupla com os paths para todas as imagens\n",
    "        labels: lista ou tuple\n",
    "            Uma lista ou tupla com o label de todas as imagens. Obviamente, precisa dar match com o os paths\n",
    "        my_transform: None ou torchvision.transforms\n",
    "            Uma sequência de transformadores para aplicar nos dados. Se for None, ele apenas transforma em tensor\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.imgs_path = imgs_path\n",
    "        self.labels = labels\n",
    "        \n",
    "        # se my_transform for None, precisamos garantir que a imagem PIL seja transformada em Tensor para nao \n",
    "        # obtermos um erro quando usarmos o dataloader (ver aulas passadas)        \n",
    "        if my_transform is not None:\n",
    "            self.transform = my_transform\n",
    "        else:\n",
    "            self.transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "    def __len__(self):     \n",
    "        \"\"\"\n",
    "        Sobrecarga do método len para obtermos o tamanho do dataset. Não é obrigatório implementar\n",
    "        \"\"\"\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):        \n",
    "        \"\"\"\n",
    "        Esse método obtém uma imagem e um label cada vez que iteramos no Dataset. Ele também aplica a transformação\n",
    "        na imagem. É obrigatório sua implementação\n",
    "        \n",
    "        item: int \n",
    "            Um indice no intervalo [0, ..., len(img_paths)-1]\n",
    "        \n",
    "        return: tuple \n",
    "             Uma tupla com a imagem, label e ID da imagem correspondentes ao item\n",
    "        \"\"\"\n",
    "\n",
    "        # Aqui usamos PIL para carregar as imagens\n",
    "        image = Image.open(self.imgs_path[item]).convert(\"RGB\")\n",
    "\n",
    "        # Aplicando as transformações\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # Obtendo o ID da imagem\n",
    "        img_id = self.imgs_path[item].split('/')[-1].split('.')[0]\n",
    "\n",
    "        if self.labels is None:\n",
    "            labels = []\n",
    "        else:\n",
    "            labels = self.labels[item]\n",
    "\n",
    "        return image, labels, img_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4607d58-02c8-4f19-8bc0-d53076c79561",
   "metadata": {},
   "source": [
    "### Preparando dados para criarmos um dataset\n",
    "- A nossa classe espera receber uma lista de imagens e labels. Portanto, precisamos preparar isso primeiro\n",
    "- Como exemplo, vamos carregar um dataset chamado felinos\n",
    "    - Ele contém imagens de 4 felines: leão, leopardo, tigre e gato\n",
    "    - A ideia é criar um classificador para identificar o felino\n",
    "    - Mas primeiro, precisamos carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3105b12-b75e-4f00-acad-8aed810dbc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b86514-d799-435d-8ce5-57c22f0b0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"/home/patcha/datasets/felinos/train\"\n",
    "test_data_path = \"/home/patcha/datasets/felinos/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81ab73-a59b-4501-804a-92e213fdfd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name = glob(os.path.join(train_data_path, \"*\"))\n",
    "labels_name = [l.split(os.path.sep)[-1] for l in labels_name]\n",
    "labels_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224c516-e4f4-436f-bcd6-8289479a0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_and_labels(path, lab_names):\n",
    "    imgs_path, labels = list(), list()\n",
    "    lab_cnt = 0\n",
    "    for lab in lab_names:    \n",
    "        paths_aux = glob(os.path.join(path, lab, \"*.jpg\"))\n",
    "        \n",
    "        # Atualizando os labels e imgs_paths\n",
    "        labels += [lab_cnt] * len(paths_aux)\n",
    "        imgs_path += paths_aux\n",
    "        \n",
    "        lab_cnt += 1\n",
    "        \n",
    "    return imgs_path, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8294d-5028-46be-b7d8-6ca82e84856d",
   "metadata": {},
   "source": [
    "- Obtendo paths e labels para cada partição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9baefd6-ab66-4866-b313-00d6d2dc1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_paths, train_labels = get_paths_and_labels(train_data_path, labels_name)\n",
    "test_imgs_paths, test_labels = get_paths_and_labels(test_data_path, labels_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c700b-5822-4622-99ca-6816c22e8669",
   "metadata": {},
   "source": [
    "- Alguns testes de sanidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f40a0-a7ff-4495-931a-13a2dd574bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_imgs_paths), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4e908-ecd5-4a83-9036-dc1ee468bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_paths[120], test_labels[120]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5ae47-557d-43e8-9209-0cbd201c5f88",
   "metadata": {},
   "source": [
    "### Instanciando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32175df5-b75f-4228-bcab-98977995b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_imgs_paths, train_labels)\n",
    "test_dataset = MyDataset(test_imgs_paths, test_labels)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec262c1-a192-4226-a01d-067ac118d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label, idimg = train_dataset[80]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title(idimg + \" | \" + labels_name[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf209b-abca-4f9c-a3dd-66f543aa4854",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Criando um Dataloader\n",
    "- Agora, podemos criar um [dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) como fizemos nas últimas duas aulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213164a5-937b-446a-ad2a-dadf4ee81f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7ed75-cd5c-441c-b378-037f4163dc6f",
   "metadata": {},
   "source": [
    "## Gerenciamento de checkpoints\n",
    "- Criar checkpoints durante o treinamento é essêncial para nao perdermos todo o trabalho em caso de algum problema\n",
    "- O Pytorch disponibiliza os métodos `torch.save()` e `torch.load()` para auxiliar nesse gerenciamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ef168-5538-4d0e-af00-d792bdddb2b9",
   "metadata": {},
   "source": [
    "- Todos os pesos de um modelo são mantidos em um dicionário interno chamado `state_dict`, eles podem ser persistidos usando `torch.save()` e recuperados usando `torch.load()`\n",
    "    - Já fizemos isso nas aulas passadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808c5c1-c6b0-4c58-84a2-fc0e406f2710",
   "metadata": {},
   "source": [
    "```\n",
    "torch.save(model.state_dict(), 'model_conv.pth')\n",
    "(...)\n",
    "\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "(...)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e796850-7c3e-42fe-b638-9e4efa671a2a",
   "metadata": {},
   "source": [
    "- Acontece que apenas salvar essas informações não é suficiente para continuar um treinamento a partir de uma época específica\n",
    "- Para isso, é interessante que a gente salve mais informações, como feito a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ef27c-7cfb-445a-b72a-51bb052082ba",
   "metadata": {},
   "source": [
    "```\n",
    "checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt_fn.state_dict(),\n",
    "        'loss': loss_fn,\n",
    "    }\n",
    "\n",
    "torch.save(checkpoint, \"my_checkpoint.pth\")\n",
    "\n",
    "(...)\n",
    "\n",
    "checkpoint = torch.load(\"my_checkpoint.pth\")\n",
    "\n",
    "(...)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_fn.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss_fn = checkpoint['loss']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23938c-f62c-4c5e-96ed-728bc55f9703",
   "metadata": {},
   "source": [
    "- Além disos, podemos escolher quando salvar checkpoits. Por exemplo:\n",
    "    - Salvar todas épocas (pode usar muito espaço de disco)\n",
    "    - Sobrepor a última época\n",
    "    - Salvar apenas o melhor resultado\n",
    "    - Salvar o melhor e a última\n",
    "    - etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de75a0-eefc-4a96-b25a-502688b3bff2",
   "metadata": {},
   "source": [
    "- Para exemplificar esse gerenciamento, precisamos criar um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa362d3",
   "metadata": {},
   "source": [
    "## Criando uma CNN\n",
    "- Vamos criar uma CNN para classificar os felinos\n",
    "- Para facilitar o projeto, vamos criar uma função que calcula o tamanho da saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638910fa-1d3f-4d96-90a3-d0681aa6a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "get_dim_size = lambda sin, sker, spad, stride: np.floor(((sin - sker + 2*spad) / stride) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6b496-e43a-4a4d-b097-055501b36e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dim_size(54, 7, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2), # 109\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) # 54\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=7, stride=2), # 24\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=4)) # 6\n",
    "        self.fc = nn.Linear(576, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)        \n",
    "        out = self.layer2(out)\n",
    "        # Fazendo a operação de flatten        \n",
    "        out = out.reshape(out.size(0), -1)        \n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7bdf2",
   "metadata": {},
   "source": [
    "- Agora podemos instanciar o nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc94922",
   "metadata": {},
   "source": [
    "- Agora podemos determinar nossa função de custo e otimizador\n",
    "- Para esse notebook vamos aproveitar o que já fizemos no anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a2ad1",
   "metadata": {},
   "source": [
    "- Agora vamos fazer nosso loop de treinamento\n",
    "- Agora, vamos mandar nosso modelo para GPU se ela estiver disponível\n",
    "- **Novo**: vamos criar nosso pipeline de checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Movendo o modelo para o device alvo\n",
    "model.to(device)\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for k, (batch_images, batch_labels, id_img) in enumerate(train_dataloader):  \n",
    "        \n",
    "        # Aplicando um flatten na imagem e movendo ela para o device alvo\n",
    "        batch_images = batch_images.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Fazendo a forward pass\n",
    "        # observe que o modelo é agnóstico ao batch size\n",
    "        outputs = model(batch_images)\n",
    "        loss = loss_func(outputs, batch_labels)\n",
    "        \n",
    "        # Fazendo a otimização\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        \n",
    "        \n",
    "    # Salvando o checkpoint da última época\n",
    "    checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_func,\n",
    "            'loss_val': loss.item()\n",
    "    }        \n",
    "    torch.save(checkpoint, \"last_checkpoint.pth\")\n",
    "\n",
    "    # Salvando a mellhor execução\n",
    "    nb = \"No\"\n",
    "    if loss < best_loss:\n",
    "        nb = \"Yes\"\n",
    "        best_loss = loss\n",
    "        torch.save(checkpoint, \"best_checkpoint.pth\")\n",
    "        \n",
    "    \n",
    "    print (f\"- Epoch [{epoch+1}/{num_epochs}] | Loss: {loss.item():.4f} | New best? {nb}\")                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf3356",
   "metadata": {},
   "source": [
    "### Fazendo inferência no conjunto de teste\n",
    "- A inferência é basicamente igual a do notebook anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdaec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    for images, labels, img_id in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8c5b5-cb4f-4e76-ab5b-1b57a200dd9c",
   "metadata": {},
   "source": [
    "___\n",
    "# Exercícios\n",
    "- Crie um conjunto de funções para gerenciar seus checkpoints\n",
    "- Faça adaptações no codigo para continuar o treinamento a partir de um checkpoint\n",
    "- Comece a criar seu pipeline de treinamento de um modelo fora do notebook\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
