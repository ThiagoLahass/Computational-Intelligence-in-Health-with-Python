{"cells":[{"cell_type":"markdown","id":"e9cec3b0-968c-48a8-b37c-13f6341fa6d0","metadata":{"id":"e9cec3b0-968c-48a8-b37c-13f6341fa6d0"},"source":["# Diferenciação automática (autograd)\n","- Essa é uma das grandes vantagens do framework: derivar qualquer função automáticamente\n","- Nem precisa dizer o quão útil isso é para aplicarmos os algoritmos baseados em descida do gradiente"]},{"cell_type":"code","execution_count":null,"id":"9f30950d-8364-4fa5-a86f-aad373110d75","metadata":{"id":"9f30950d-8364-4fa5-a86f-aad373110d75"},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","id":"4deb3208-abbe-4ab7-88b5-01c5961faf02","metadata":{"id":"4deb3208-abbe-4ab7-88b5-01c5961faf02"},"source":["## Exemplo 1:"]},{"cell_type":"code","execution_count":null,"id":"374ec7d2-7d26-45ad-8fbd-0c31ff97e2df","metadata":{"id":"374ec7d2-7d26-45ad-8fbd-0c31ff97e2df"},"outputs":[],"source":["x = torch.randn(3, requires_grad=True)\n","x"]},{"cell_type":"markdown","id":"44d334c6-84c9-41f2-8420-1a1bffe19585","metadata":{"id":"44d334c6-84c9-41f2-8420-1a1bffe19585"},"source":["- O atributo `requires_grad=True` informa ao Pytorch que é necessário fazer o tracking dessa variável para calcular alguma derivada\n","- O padrão é que seja `False`"]},{"cell_type":"code","execution_count":null,"id":"716d4128-a611-4077-af01-d8670e0a357e","metadata":{"id":"716d4128-a611-4077-af01-d8670e0a357e"},"outputs":[],"source":["y = x + 2\n","y"]},{"cell_type":"markdown","id":"3070a178-b588-402d-936a-d682ebf2613e","metadata":{"id":"3070a178-b588-402d-936a-d682ebf2613e"},"source":["- Observe que o Pytorch cria automaticamente um `grad_fn=<AddBackward0>`\n","- Isso é o grafo automático para calculo de $\\frac{\\partial y}{\\partial x}$\n","- O valor que já é armazenado para `y` é por conta da forward pass, que é o resultado da operação"]},{"cell_type":"code","execution_count":null,"id":"87fa4f27-c64c-4ea6-8d16-4847a9374d3f","metadata":{"id":"87fa4f27-c64c-4ea6-8d16-4847a9374d3f"},"outputs":[],"source":["z = y*y*2\n","z = z.mean()\n","z"]},{"cell_type":"markdown","id":"c3b0ba65-13ce-43b0-b044-bd58bca1fbde","metadata":{"id":"c3b0ba65-13ce-43b0-b044-bd58bca1fbde"},"source":["- Agora, observe que a função automática mudou para `MeanBackward0`, que é a operação final de `z`"]},{"cell_type":"markdown","id":"b2e2c802-18ad-42de-98fe-d9fa6d88249f","metadata":{"id":"b2e2c802-18ad-42de-98fe-d9fa6d88249f"},"source":["- Agora, se quisermos calcular o gradiente, a única coisa que precisamos fazer é chamar o método `backward()` na função final que desejamos calcular o gradiente\n","    - Essa ideia vem do backpropagation que discutimos na última aula"]},{"cell_type":"code","execution_count":null,"id":"5d768924-3ae8-4ee2-9696-0137573ede0f","metadata":{"id":"5d768924-3ae8-4ee2-9696-0137573ede0f"},"outputs":[],"source":["z.backward()"]},{"cell_type":"markdown","id":"6253fd44-bd64-473b-837d-8da1525e9afd","metadata":{"id":"6253fd44-bd64-473b-837d-8da1525e9afd"},"source":["- Agora, podemos obter o gradiente $\\frac{\\partial z}{\\partial x}$ da seguinte forma:"]},{"cell_type":"code","execution_count":null,"id":"04eca9d1-292f-4145-958a-fb77614c88f3","metadata":{"id":"04eca9d1-292f-4145-958a-fb77614c88f3"},"outputs":[],"source":["x.grad"]},{"cell_type":"markdown","id":"2c6b63ba-105a-4801-af2e-e08bad402260","metadata":{"id":"2c6b63ba-105a-4801-af2e-e08bad402260"},"source":["- Esse valor é obtido através do grafo automático que foi criado\n","- **Obs:** se tentarmos obter o gradiente sem nenhum `requires_grad` setado, vamos obter um erro"]},{"cell_type":"markdown","id":"97f6551a-5833-41d2-881b-5ffe5a961279","metadata":{"id":"97f6551a-5833-41d2-881b-5ffe5a961279"},"source":["## Exemplo 2:"]},{"cell_type":"code","execution_count":null,"id":"3d5feae2-e868-4edc-a2c3-860b711190b1","metadata":{"id":"3d5feae2-e868-4edc-a2c3-860b711190b1"},"outputs":[],"source":["x = torch.tensor(1.0, requires_grad=True)\n","y = torch.tensor(2.0, requires_grad=True)\n","z = 2*x + y**2"]},{"cell_type":"code","execution_count":null,"id":"0d09dade-19b8-4ab0-87be-1110fcccc521","metadata":{"id":"0d09dade-19b8-4ab0-87be-1110fcccc521"},"outputs":[],"source":["z"]},{"cell_type":"code","execution_count":null,"id":"378e16f5-27e7-4bd4-9a74-38b85eb32d87","metadata":{"id":"378e16f5-27e7-4bd4-9a74-38b85eb32d87"},"outputs":[],"source":["z.backward()"]},{"cell_type":"code","execution_count":null,"id":"ea3b7678-0e36-413f-b573-c5a40e71fad1","metadata":{"id":"ea3b7678-0e36-413f-b573-c5a40e71fad1"},"outputs":[],"source":["x.grad"]},{"cell_type":"code","execution_count":null,"id":"fd091d4b-cfc5-4cf0-912d-6b586e85ff69","metadata":{"id":"fd091d4b-cfc5-4cf0-912d-6b586e85ff69"},"outputs":[],"source":["y.grad"]},{"cell_type":"markdown","id":"62ea0241-dd2c-4adb-9a08-c3e42fc1b2d7","metadata":{"id":"62ea0241-dd2c-4adb-9a08-c3e42fc1b2d7"},"source":["## Removendo a obrigatoriedade de calcular o gradiente\n","- Temos 3 opções"]},{"cell_type":"code","execution_count":null,"id":"c627f27e-3853-4b50-aa8c-65bc0c987b9a","metadata":{"id":"c627f27e-3853-4b50-aa8c-65bc0c987b9a"},"outputs":[],"source":["x.requires_grad = False\n","x"]},{"cell_type":"code","execution_count":null,"id":"0af2872b-07d9-4747-871d-a9db227cefa3","metadata":{"id":"0af2872b-07d9-4747-871d-a9db227cefa3"},"outputs":[],"source":["x.detach()"]},{"cell_type":"code","execution_count":null,"id":"0e7eaa8b-d281-4879-b0d7-370bb5882990","metadata":{"id":"0e7eaa8b-d281-4879-b0d7-370bb5882990"},"outputs":[],"source":["x = torch.tensor(1.0, requires_grad=True)\n","with torch.no_grad():\n","    y = 2*x\n","\n","y"]},{"cell_type":"code","execution_count":null,"id":"d88bc696-57ac-4143-8265-31f581edf02e","metadata":{"id":"d88bc696-57ac-4143-8265-31f581edf02e"},"outputs":[],"source":["y = 2*x\n","y"]},{"cell_type":"markdown","id":"357bd62f-3776-4422-89f0-7f0a193c2b14","metadata":{"id":"357bd62f-3776-4422-89f0-7f0a193c2b14"},"source":["## Zerando o valor dos gradientes\n","- Por padrão, os gradientes são acumulados dentro do atributo `grad`"]},{"cell_type":"code","execution_count":null,"id":"cf76a35c-9f56-4f1b-a56e-873c9bd4e5e9","metadata":{"id":"cf76a35c-9f56-4f1b-a56e-873c9bd4e5e9"},"outputs":[],"source":["w = torch.ones(4, requires_grad=True)\n","\n","for ep in range(4):\n","    loss = (w * 3).sum()\n","    loss.backward()\n","\n","    print(w.grad)"]},{"cell_type":"markdown","id":"36b12c77-2fc6-4bdd-8c43-afceadbb1d91","metadata":{"id":"36b12c77-2fc6-4bdd-8c43-afceadbb1d91"},"source":["- A maneira de solucionar esse comportamento é zerando os gradientes após o loop\n","- Isso é importante quando fizermos nosso loop de treinamento"]},{"cell_type":"code","execution_count":null,"id":"7587b331-780f-4fc2-92b0-902b4e6d064e","metadata":{"id":"7587b331-780f-4fc2-92b0-902b4e6d064e"},"outputs":[],"source":["w = torch.ones(4, requires_grad=True)\n","\n","for ep in range(3):\n","    loss = (w * 3).sum()\n","    loss.backward()\n","\n","    print(w.grad)\n","\n","    w.grad.zero_()"]},{"cell_type":"markdown","id":"21595ff8-6523-45e1-a5ea-d7986791a6dc","metadata":{"tags":[],"id":"21595ff8-6523-45e1-a5ea-d7986791a6dc"},"source":["# Indo mais a fundo\n","- Se você quiser entender mais a fundo como é construído o grafo para a derivação automática, sugiro que assita o vídeo a seguir:"]},{"cell_type":"code","execution_count":null,"id":"ef0d996e-fb4c-49aa-98a2-a5b0bbc61b16","metadata":{"id":"ef0d996e-fb4c-49aa-98a2-a5b0bbc61b16"},"outputs":[],"source":["from IPython.display import YouTubeVideo\n","YouTubeVideo('MswxJw-8PvE', width=600, height=400)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}