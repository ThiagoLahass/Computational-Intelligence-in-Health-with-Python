{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003a9cd1",
   "metadata": {},
   "source": [
    "# Aprendendo mais conceitos construindo uma FNN com Pytorch\n",
    "- A intenção desse Notebook é aprendermos mais alguns conceitos muito importantes já implementando uma rede neural\n",
    "- Os conceitos são:\n",
    "     - Carregar um dataset usando `torchvision.datasets`\n",
    "     - Entender o `torch.utils.data.Dataset`\n",
    "     - Entender o `torchvision.transform`\n",
    "     - Aprender a usar um `Dataloader`\n",
    "     - Criar um modelo estendendo a classe `nn.Module`\n",
    "     - Treinar a rede em uma GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365574c",
   "metadata": {},
   "source": [
    "## Utilizando a base CIFAR10\n",
    "- [Dataset muito famoso](https://www.cs.toronto.edu/~kriz/cifar.html) que contém 60k imagens coloridas 32 x 32 com 10 classes de 6k imagens por classe\n",
    "- O conjunto de teste possui 10k imagens\n",
    "- Vamos carregar ela utilizando  `torchvision.datasets` \n",
    "    - `torchvision` é um pacote do PyTorch que contém datasets, modelos e transformações famosas da área de deep learning\n",
    "    - Vamos usar bastante esse pacote nesse módulo\n",
    "    - [Documentação](https://pytorch.org/vision/stable/index.html)   \n",
    "- Vamos começar usando `torchvision.datasets.CIFAR10`\n",
    "    - [Documentação](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10)\n",
    "- Para facilitar o tempo de execução, vamos carregar apenas o conjunto de teste (10k imagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ff2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dataset = torchvision.datasets.CIFAR10(root=\"/home/patcha/datasets\", \n",
    "                                             train=False, \n",
    "                                             download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b577d8",
   "metadata": {},
   "source": [
    "- O Pytorch tem uma classe especial chamada `torch.utils.data.Dataset`\n",
    "    - [Documentação](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset)\n",
    "- Ela é uma maneira de preparar e carregar dados dentro do framework\n",
    "- Ela implementa a `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cifar_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a14362",
   "metadata": {},
   "source": [
    "- O Pytorch utiliza uma biblioteca para manipulação de imagens chamada [Pillow](https://pillow.readthedocs.io/en/stable/reference/Image.html)\n",
    "    - Por enquanto, apenas aceite que ela carrega imagens assim como o OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e917a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = cifar_dataset[2]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57873e",
   "metadata": {},
   "source": [
    "- Agora vamos criar um `Dataloader`, que nada mais é do que um classe que vai criar um `Generator` usando um `Dataset`\n",
    "    - [Documentação](https://pytorch.org/docs/stable/data.html)\n",
    "- **Nota**: se você não sabe nada sobre generators, eu sugiro a [leitura desse post](https://realpython.com/introduction-to-python-generators/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(dataset=cifar_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0b3a6",
   "metadata": {},
   "source": [
    "- Podemos acessar dados de um dataloader dentro de um loop\n",
    "- Porém, tem um problema: **dataloaders não aceitam PIL como entrada**\n",
    "    - Se rodarmos o código abaixo vamos obter um erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, labels in train_loader:\n",
    "    plt.imshow(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50365661",
   "metadata": {},
   "source": [
    "- Precisamos uma maneira de converter os dados para tensores ou `np.ndarray`\n",
    "- Felizmente, a `torchvision` possui um submódulo para aplicar transformações nos dados\n",
    "    - [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html)\n",
    "- É muito útil para aplicarmos data augmentation, mas isso é tema para próxima aula\n",
    "- Aqui, vamos usar apenas o `transforms.ToTensor()`, que converte um PIL ou `np.ndarray` para um tensor\n",
    "- Na verdade, podemos fazer isso dentro da chamada do `datasets` do Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbccddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dataset = torchvision.datasets.CIFAR10(root=\"/home/patcha/datasets\", \n",
    "                                             train=False, \n",
    "                                             download=True,\n",
    "                                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf3fe6",
   "metadata": {},
   "source": [
    "- Agora, os dados das imagens serão tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35968cc",
   "metadata": {},
   "source": [
    "- E podemos recriar nosso `Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(dataset=cifar_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f845e",
   "metadata": {},
   "source": [
    "- E podemos acessar também:\n",
    "    - Porém, sempre é retornado um batch de imagens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_img, batch_labels in train_loader:\n",
    "    print(batch_img.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af15fd9",
   "metadata": {},
   "source": [
    "- Essa é uma boa hora para entender esse tensor\n",
    "- No Pytorch, quando trabalhamos com imagens, sempre teremos:\n",
    "    - Dimensão 0: batch size\n",
    "    - Dimensão 1: canais da imagem\n",
    "    - Dimensão 2: width\n",
    "    - Dimensão 3: height           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa362d3",
   "metadata": {},
   "source": [
    "## Criando uma rede neural do tipo Feedforward\n",
    "- Agora vamos criar nossa rede neural\n",
    "- A maneira padrão de criar redes neurais dentro do Pytorch é estendendo a classe `nn.Module`\n",
    "- Você pode imaginar a criação de redes como conjunto de blocos que vamos compondo\n",
    "    - Como um LEGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_labels):\n",
    "        super(FNN, self).__init__()\n",
    "        \n",
    "        # Aqui vamos definir a arquitetura da rede\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_labels)  \n",
    "        self.soft = nn.Softmax(num_labels)\n",
    "\n",
    "    def forward(self, x, apply_soft=False):\n",
    "        \"\"\"\n",
    "        Esse método precisa ser criado para fazermo o forward pass da rede\n",
    "        \"\"\"\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        if apply_soft:\n",
    "            out = self.soft(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7bdf2",
   "metadata": {},
   "source": [
    "- Agora podemos instanciar o nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32*32*3\n",
    "model = FNN(input_size, 20, 10)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc94922",
   "metadata": {},
   "source": [
    "- Agora podemos determinar nossa função de custo e otimizador\n",
    "- Para esse notebook vamos usar a Entropia cruzada e o otimizador Adam (uma variação do gradiente descendente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a2ad1",
   "metadata": {},
   "source": [
    "- Agora vamos fazer nosso loop de treinamento\n",
    "- Agora, vamos mandar nosso modelo para GPU se ela estiver disponível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Movendo o modelo para o device alvo\n",
    "model.to(\"cuda\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for k, (batch_images, batch_labels) in enumerate(train_loader):  \n",
    "        \n",
    "        # Aplicando um flatten na imagem e movendo ela para o device alvo\n",
    "        batch_images = batch_images.reshape(-1, 32*32*3).to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Fazendo a forward pass\n",
    "        # observe que o modelo é agnóstico ao batch size\n",
    "        outputs = model(batch_images)\n",
    "        loss = loss_func(outputs, batch_labels)\n",
    "        \n",
    "        # Fazendo a otimização\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "    \n",
    "    print (f\"- Epoch [{epoch+1}/{num_epochs}] | Loss: {loss.item():.4f}\")                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf3356",
   "metadata": {},
   "source": [
    "### Fazendo inferência\n",
    "- Como estamos usando apenas um pedaço do dataset, vamos fazer um exemplo de inferência com um pedaço do conjunto de treino\n",
    "    - O ideal era ter validação e teste\n",
    "- A inferência é basicamente igual a do notebook anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdaec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.reshape(-1, 32*32*3).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9237a7",
   "metadata": {},
   "source": [
    "- Salvando o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db586f",
   "metadata": {},
   "source": [
    "___\n",
    "# Exercício\n",
    "- Estude o código desse notebook e faça as seguinte adaptações:\n",
    "    - Carregue os dados da CIFAR10 inteiro (teste e treino)\n",
    "    - Divida os conjuntos em treino, teste e validação\n",
    "    - Inclua uma avaliação das métricas para o conjunto de validação e acompanhe as curvas de aprendizado\n",
    "    - Faça a inferência no conjunto de teste e compare com a validação\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
