{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando a qualidade do modelo via cross validation\n",
    "Esse notebook faz parte do material de apoio do tutorial [Introdução ao Scikit-learn - Parte 3: avaliando o modelo via cross validation](http://computacaointeligente.com.br/outros/intro-sklearn-part-3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset = load_wine()\n",
    "X = wine_dataset['data']\n",
    "y = wine_dataset['target']\n",
    "nome_das_classes = wine_dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o pipeline e executando N vezes\n",
    "Antes de executarmos o *cross-validation* vamos executar o modelos `N` vezes. Mas dessa vez, sempre antes de treinar o modelo, vamos embaralhar a base (perceba que não setamos o parâmetro `random_state`. Por default ele fica como `None`).\n",
    "\n",
    "Nesse experimento, calculamos a média da acurácia. Fica como exercício fazer o mesmo para a matriz de confusão, que foi calculada na parte 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Acurácia:\n",
      "Media: 95.56%\n",
      "Desvio padrão: 2.37%\n",
      "\n",
      "Matriz de confusão média:\n",
      "Media:\n",
      "[[18.6  0.   0. ]\n",
      " [ 0.7 18.6  1.4]\n",
      " [ 0.   0.3 14.4]]\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "N = 10\n",
    "acuracias = list()\n",
    "\n",
    "matrizes_conf = list()\n",
    "\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "  (\"normalizacao\", MinMaxScaler()),  \n",
    "  (\"KNN\", KNeighborsClassifier(n_neighbors=K))\n",
    "])\n",
    "\n",
    "for i in range(N):\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "    knn_pipeline.fit(X_treino, y_treino)\n",
    "    ac_i = knn_pipeline.score(X_teste, y_teste)\n",
    "    acuracias.append(ac_i)\n",
    "\n",
    "    y_pred = knn_pipeline.predict(X_teste)\n",
    "    mat_conf_i = confusion_matrix(y_teste, y_pred)\n",
    "    matrizes_conf.append(mat_conf_i)\n",
    "\n",
    "print(\"- Acurácia:\")\n",
    "print(f\"Media: {round(np.mean(acuracias) * 100, 2)}%\")\n",
    "print(f\"Desvio padrão: {round(np.std(acuracias) * 100, 2)}%\")\n",
    "\n",
    "matrizes_conf_media = np.zeros_like(matrizes_conf[0], dtype=float)\n",
    "for matriz in matrizes_conf:\n",
    "    matrizes_conf_media += matriz / len(matrizes_conf)\n",
    "\n",
    "print(\"\\nMatriz de confusão média:\")\n",
    "print(f\"Media:\\n{matrizes_conf_media}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando cross-validation\n",
    "Ok, agora vamos utilizar cross-validation. Mas primeiro, precisamos do modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline(steps=[\n",
    "  (\"normalizacao\", MinMaxScaler()),  \n",
    "  (\"KNN\", KNeighborsClassifier(n_neighbors=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando `cross_val_score`\n",
    "Essa função básicamente executa o cross-validation de acordo com o número de *folders* informada via o parâmetro `cv`. Na sequência ela retorna uma métrica de performance para cada folder de teste. Por padrão, essa métrica é a acurácia (para classificação). Mas podemos definir usando o parâmetro `scoring`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracias: [0.91666667 0.94444444 1.         1.         0.91428571]\n",
      "acuracia final: 0.9550793650793651 +- 0.03817980032602645\n"
     ]
    }
   ],
   "source": [
    "acuracias = cross_val_score(knn_pipeline, X, y, cv=5)\n",
    "print(\"acuracias:\", acuracias)\n",
    "print(\"acuracia final:\", np.mean(acuracias), \"+-\", np.std(acuracias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro: [0.9162963  0.94515263 1.         1.         0.91764133]\n",
      "F1-macro: 0.9558180493969968 +- 0.03751605524409954\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(knn_pipeline, X, y, cv=5, scoring=\"f1_macro\")\n",
    "print(\"F1-macro:\", f1s)\n",
    "print(\"F1-macro:\", np.mean(f1s), \"+-\", np.std(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando `cross_validate`\n",
    "A principal diferença para o método anterior é que podemos setar várias métricas. Além disso, ele sempre retorna o tempo de `fit` e de `score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- fit_time:\n",
      "-- [0.00129795 0.00153828 0.00146532 0.00215125 0.00225377]\n",
      "-- 0.001741313934326172 +- 0.0003859087222483761\n",
      "\n",
      "- score_time:\n",
      "-- [0.00671172 0.00605178 0.00701642 0.00863791 0.00928473]\n",
      "-- 0.007540512084960938 +- 0.0012185628426625607\n",
      "\n",
      "- test_accuracy:\n",
      "-- [0.91666667 0.94444444 1.         1.         0.91428571]\n",
      "-- 0.9550793650793651 +- 0.03817980032602645\n",
      "\n",
      "- test_precision_macro:\n",
      "-- [0.91538462 0.94405594 1.         1.         0.91538462]\n",
      "-- 0.9549650349650349 +- 0.03823224723760816\n",
      "\n",
      "- test_recall_macro:\n",
      "-- [0.91904762 0.95238095 1.         1.         0.93333333]\n",
      "-- 0.9609523809523809 +- 0.03359084207342554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_metricas = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "metricas = cross_validate(knn_pipeline, X, y, cv=5, scoring=nome_metricas)\n",
    "for met in metricas:\n",
    "    print(f\"- {met}:\")\n",
    "    print(f\"-- {metricas[met]}\")\n",
    "    print(f\"-- {np.mean(metricas[met])} +- {np.std(metricas[met])}\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando predições via `cross_val_predict`\n",
    "Nesse caso, cada predição será obtida para o conjunto de teste de cada uma das *folders*. Em outras palavras, se `cv=5`, por exemplo, o modelo vai ser treinado para 4 partições e testado em 1, que gera as predições. Ao final das 5 execuções, os resultados são concatenados e retornados.\n",
    "\n",
    "Podemos setar o parametro `method` para escolher qual predição será retornada.\n",
    "\n",
    "**Observação**: os resultados para os dois métodos a seguir podem ser diferentes pois o modelo será retreinado para cada partição (que pode ser diferente). Vamos lidar com isso na sequência usando o `KFold`-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 1 1 0 1 0\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 2 1 1 0 1 0 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(knn_pipeline, X, y, cv=5)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pred_prob = cross_val_predict(knn_pipeline, X, y, cv=5, method=\"predict_proba\")\n",
    "print(pred_prob[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo mais controle utilizando `KFold` e  `StratifiedKFold` \n",
    "Ambas as classes retornam um *generator* com os indices para selecionar os dados de acordo com o número de *folders* informadas. A principal diferença é que o `StratifiedKFold` estratifica os dados de acordo com as classes. Em outras palavras, ele balanceia a quantidade de amostras de cada classe entre as *folders*. Isso é relevante se o dataset é desbalanceado, algo comum em ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `KFold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['folder_1', 'folder_2', 'folder_3', 'folder_4', 'folder_5'])\n"
     ]
    }
   ],
   "source": [
    "n_folders = 5\n",
    "cross_val = KFold(n_splits=n_folders, shuffle=True, random_state=32)\n",
    "dados_cv = {f\"folder_{f+1}\": {\"treino\": None, \"teste\": None} for f in range(n_folders)}\n",
    "k = 1\n",
    "for indices_treino, indices_teste in cross_val.split(X):\n",
    "    dados_cv[f\"folder_{k}\"][\"treino\"] = (X[indices_treino], y[indices_treino])\n",
    "    dados_cv[f\"folder_{k}\"][\"teste\"] = (X[indices_teste], y[indices_teste])\n",
    "    k+=1\n",
    "print(dados_cv.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções `cross_val_predict`, `cross_validate` e `cross_val_predict` aceitam que o parâmetro `cv` seja uma instancia da classe `KFold`-like por exemplo. Isso garante que as partições sejam exatamente as mesmas e evita o problema citado quando usamos `method=\"predict_proba\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(knn_pipeline, X, y, cv=cross_val)\n",
    "pred_prob = cross_val_predict(knn_pipeline, X, y, cv=cross_val, method=\"predict_proba\")\n",
    "print(pred[112])\n",
    "print(pred_prob[112])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos tomar controle do loop de execução do modelo. A gente iniciou esse notebook executando o modelo`n` vezes para partições diferentes de treino e teste. Podemos fazer o mesmo, mas agora usando as *folders*. Isso é que as funções anteriores fazem por trás do pano. Mas por algum motivo, você pode querer controlar esse loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_1: 0.9722222222222222\n",
      "folder_2: 0.9722222222222222\n",
      "folder_3: 0.9166666666666666\n",
      "folder_4: 0.9142857142857143\n",
      "folder_5: 1.0\n",
      "\n",
      "- Acurácia das folders:\n",
      "Media: 95.51%\n",
      "Desvio padrão: 3.39%\n"
     ]
    }
   ],
   "source": [
    "acuracias = list()\n",
    "for folder in dados_cv:       \n",
    "    knn_pipeline.fit(dados_cv[folder][\"treino\"][0], dados_cv[folder][\"treino\"][1])\n",
    "    ac_i = knn_pipeline.score(dados_cv[folder][\"teste\"][0], dados_cv[folder][\"teste\"][1])\n",
    "    acuracias.append(ac_i)\n",
    "    print(f\"{folder}: {ac_i}\")\n",
    "\n",
    "print(\"\\n- Acurácia das folders:\")\n",
    "print(f\"Media: {round(np.mean(acuracias) * 100, 2)}%\")\n",
    "print(f\"Desvio padrão: {round(np.std(acuracias) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `StratifiedKFold`\n",
    "A ideia é basicamente a mesma da `KFold`, mas como vai ser estratificado por classe, precisamos passar `y` como parâmetro. Você pode substituir o *generator* obtido aqui para nas células anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['folder_1', 'folder_2', 'folder_3', 'folder_4', 'folder_5'])\n"
     ]
    }
   ],
   "source": [
    "n_folders = 5\n",
    "cross_val_strat = StratifiedKFold(n_splits=n_folders, shuffle=True, random_state=32)\n",
    "dados_cv_strat = {f\"folder_{f+1}\": {\"treino\": None, \"teste\": None} for f in range(n_folders)}\n",
    "k = 1\n",
    "for indices_treino, indices_teste in cross_val_strat.split(X, y):\n",
    "    dados_cv[f\"folder_{k}\"][\"treino\"] = (X[indices_treino], y[indices_treino])\n",
    "    dados_cv[f\"folder_{k}\"][\"teste\"] = (X[indices_teste], y[indices_teste])\n",
    "    k+=1\n",
    "print(dados_cv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'treino': (array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "          1.065e+03],\n",
       "         [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "          1.050e+03],\n",
       "         [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "          1.185e+03],\n",
       "         ...,\n",
       "         [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "          8.350e+02],\n",
       "         [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "          8.400e+02],\n",
       "         [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "          5.600e+02]]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2])),\n",
       " 'teste': (array([[1.375000e+01, 1.730000e+00, 2.410000e+00, 1.600000e+01,\n",
       "          8.900000e+01, 2.600000e+00, 2.760000e+00, 2.900000e-01,\n",
       "          1.810000e+00, 5.600000e+00, 1.150000e+00, 2.900000e+00,\n",
       "          1.320000e+03],\n",
       "         [1.475000e+01, 1.730000e+00, 2.390000e+00, 1.140000e+01,\n",
       "          9.100000e+01, 3.100000e+00, 3.690000e+00, 4.300000e-01,\n",
       "          2.810000e+00, 5.400000e+00, 1.250000e+00, 2.730000e+00,\n",
       "          1.150000e+03],\n",
       "         [1.285000e+01, 1.600000e+00, 2.520000e+00, 1.780000e+01,\n",
       "          9.500000e+01, 2.480000e+00, 2.370000e+00, 2.600000e-01,\n",
       "          1.460000e+00, 3.930000e+00, 1.090000e+00, 3.630000e+00,\n",
       "          1.015000e+03],\n",
       "         [1.305000e+01, 2.050000e+00, 3.220000e+00, 2.500000e+01,\n",
       "          1.240000e+02, 2.630000e+00, 2.680000e+00, 4.700000e-01,\n",
       "          1.920000e+00, 3.580000e+00, 1.130000e+00, 3.200000e+00,\n",
       "          8.300000e+02],\n",
       "         [1.305000e+01, 1.650000e+00, 2.550000e+00, 1.800000e+01,\n",
       "          9.800000e+01, 2.450000e+00, 2.430000e+00, 2.900000e-01,\n",
       "          1.440000e+00, 4.250000e+00, 1.120000e+00, 2.510000e+00,\n",
       "          1.105000e+03],\n",
       "         [1.388000e+01, 1.890000e+00, 2.590000e+00, 1.500000e+01,\n",
       "          1.010000e+02, 3.250000e+00, 3.560000e+00, 1.700000e-01,\n",
       "          1.700000e+00, 5.430000e+00, 8.800000e-01, 3.560000e+00,\n",
       "          1.095000e+03],\n",
       "         [1.421000e+01, 4.040000e+00, 2.440000e+00, 1.890000e+01,\n",
       "          1.110000e+02, 2.850000e+00, 2.650000e+00, 3.000000e-01,\n",
       "          1.250000e+00, 5.240000e+00, 8.700000e-01, 3.330000e+00,\n",
       "          1.080000e+03],\n",
       "         [1.438000e+01, 3.590000e+00, 2.280000e+00, 1.600000e+01,\n",
       "          1.020000e+02, 3.250000e+00, 3.170000e+00, 2.700000e-01,\n",
       "          2.190000e+00, 4.900000e+00, 1.040000e+00, 3.440000e+00,\n",
       "          1.065000e+03],\n",
       "         [1.390000e+01, 1.680000e+00, 2.120000e+00, 1.600000e+01,\n",
       "          1.010000e+02, 3.100000e+00, 3.390000e+00, 2.100000e-01,\n",
       "          2.140000e+00, 6.100000e+00, 9.100000e-01, 3.330000e+00,\n",
       "          9.850000e+02],\n",
       "         [1.305000e+01, 1.730000e+00, 2.040000e+00, 1.240000e+01,\n",
       "          9.200000e+01, 2.720000e+00, 3.270000e+00, 1.700000e-01,\n",
       "          2.910000e+00, 7.200000e+00, 1.120000e+00, 2.910000e+00,\n",
       "          1.150000e+03],\n",
       "         [1.382000e+01, 1.750000e+00, 2.420000e+00, 1.400000e+01,\n",
       "          1.110000e+02, 3.880000e+00, 3.740000e+00, 3.200000e-01,\n",
       "          1.870000e+00, 7.050000e+00, 1.010000e+00, 3.260000e+00,\n",
       "          1.190000e+03],\n",
       "         [1.422000e+01, 1.700000e+00, 2.300000e+00, 1.630000e+01,\n",
       "          1.180000e+02, 3.200000e+00, 3.000000e+00, 2.600000e-01,\n",
       "          2.030000e+00, 6.380000e+00, 9.400000e-01, 3.310000e+00,\n",
       "          9.700000e+02],\n",
       "         [1.233000e+01, 1.100000e+00, 2.280000e+00, 1.600000e+01,\n",
       "          1.010000e+02, 2.050000e+00, 1.090000e+00, 6.300000e-01,\n",
       "          4.100000e-01, 3.270000e+00, 1.250000e+00, 1.670000e+00,\n",
       "          6.800000e+02],\n",
       "         [1.221000e+01, 1.190000e+00, 1.750000e+00, 1.680000e+01,\n",
       "          1.510000e+02, 1.850000e+00, 1.280000e+00, 1.400000e-01,\n",
       "          2.500000e+00, 2.850000e+00, 1.280000e+00, 3.070000e+00,\n",
       "          7.180000e+02],\n",
       "         [1.196000e+01, 1.090000e+00, 2.300000e+00, 2.100000e+01,\n",
       "          1.010000e+02, 3.380000e+00, 2.140000e+00, 1.300000e-01,\n",
       "          1.650000e+00, 3.210000e+00, 9.900000e-01, 3.130000e+00,\n",
       "          8.860000e+02],\n",
       "         [1.270000e+01, 3.870000e+00, 2.400000e+00, 2.300000e+01,\n",
       "          1.010000e+02, 2.830000e+00, 2.550000e+00, 4.300000e-01,\n",
       "          1.950000e+00, 2.570000e+00, 1.190000e+00, 3.130000e+00,\n",
       "          4.630000e+02],\n",
       "         [1.200000e+01, 9.200000e-01, 2.000000e+00, 1.900000e+01,\n",
       "          8.600000e+01, 2.420000e+00, 2.260000e+00, 3.000000e-01,\n",
       "          1.430000e+00, 2.500000e+00, 1.380000e+00, 3.120000e+00,\n",
       "          2.780000e+02],\n",
       "         [1.184000e+01, 8.900000e-01, 2.580000e+00, 1.800000e+01,\n",
       "          9.400000e+01, 2.200000e+00, 2.210000e+00, 2.200000e-01,\n",
       "          2.350000e+00, 3.050000e+00, 7.900000e-01, 3.080000e+00,\n",
       "          5.200000e+02],\n",
       "         [1.208000e+01, 1.330000e+00, 2.300000e+00, 2.360000e+01,\n",
       "          7.000000e+01, 2.200000e+00, 1.590000e+00, 4.200000e-01,\n",
       "          1.380000e+00, 1.740000e+00, 1.070000e+00, 3.210000e+00,\n",
       "          6.250000e+02],\n",
       "         [1.181000e+01, 2.120000e+00, 2.740000e+00, 2.150000e+01,\n",
       "          1.340000e+02, 1.600000e+00, 9.900000e-01, 1.400000e-01,\n",
       "          1.560000e+00, 2.500000e+00, 9.500000e-01, 2.260000e+00,\n",
       "          6.250000e+02],\n",
       "         [1.237000e+01, 1.070000e+00, 2.100000e+00, 1.850000e+01,\n",
       "          8.800000e+01, 3.520000e+00, 3.750000e+00, 2.400000e-01,\n",
       "          1.950000e+00, 4.500000e+00, 1.040000e+00, 2.770000e+00,\n",
       "          6.600000e+02],\n",
       "         [1.242000e+01, 2.550000e+00, 2.270000e+00, 2.200000e+01,\n",
       "          9.000000e+01, 1.680000e+00, 1.840000e+00, 6.600000e-01,\n",
       "          1.420000e+00, 2.700000e+00, 8.600000e-01, 3.300000e+00,\n",
       "          3.150000e+02],\n",
       "         [1.222000e+01, 1.290000e+00, 1.940000e+00, 1.900000e+01,\n",
       "          9.200000e+01, 2.360000e+00, 2.040000e+00, 3.900000e-01,\n",
       "          2.080000e+00, 2.700000e+00, 8.600000e-01, 3.020000e+00,\n",
       "          3.120000e+02],\n",
       "         [1.161000e+01, 1.350000e+00, 2.700000e+00, 2.000000e+01,\n",
       "          9.400000e+01, 2.740000e+00, 2.920000e+00, 2.900000e-01,\n",
       "          2.490000e+00, 2.650000e+00, 9.600000e-01, 3.260000e+00,\n",
       "          6.800000e+02],\n",
       "         [1.208000e+01, 1.390000e+00, 2.500000e+00, 2.250000e+01,\n",
       "          8.400000e+01, 2.560000e+00, 2.290000e+00, 4.300000e-01,\n",
       "          1.040000e+00, 2.900000e+00, 9.300000e-01, 3.190000e+00,\n",
       "          3.850000e+02],\n",
       "         [1.145000e+01, 2.400000e+00, 2.420000e+00, 2.000000e+01,\n",
       "          9.600000e+01, 2.900000e+00, 2.790000e+00, 3.200000e-01,\n",
       "          1.830000e+00, 3.250000e+00, 8.000000e-01, 3.390000e+00,\n",
       "          6.250000e+02],\n",
       "         [1.260000e+01, 2.460000e+00, 2.200000e+00, 1.850000e+01,\n",
       "          9.400000e+01, 1.620000e+00, 6.600000e-01, 6.300000e-01,\n",
       "          9.400000e-01, 7.100000e+00, 7.300000e-01, 1.580000e+00,\n",
       "          6.950000e+02],\n",
       "         [1.336000e+01, 2.560000e+00, 2.350000e+00, 2.000000e+01,\n",
       "          8.900000e+01, 1.400000e+00, 5.000000e-01, 3.700000e-01,\n",
       "          6.400000e-01, 5.600000e+00, 7.000000e-01, 2.470000e+00,\n",
       "          7.800000e+02],\n",
       "         [1.311000e+01, 1.900000e+00, 2.750000e+00, 2.550000e+01,\n",
       "          1.160000e+02, 2.200000e+00, 1.280000e+00, 2.600000e-01,\n",
       "          1.560000e+00, 7.100000e+00, 6.100000e-01, 1.330000e+00,\n",
       "          4.250000e+02],\n",
       "         [1.323000e+01, 3.300000e+00, 2.280000e+00, 1.850000e+01,\n",
       "          9.800000e+01, 1.800000e+00, 8.300000e-01, 6.100000e-01,\n",
       "          1.870000e+00, 1.052000e+01, 5.600000e-01, 1.510000e+00,\n",
       "          6.750000e+02],\n",
       "         [1.384000e+01, 4.120000e+00, 2.380000e+00, 1.950000e+01,\n",
       "          8.900000e+01, 1.800000e+00, 8.300000e-01, 4.800000e-01,\n",
       "          1.560000e+00, 9.010000e+00, 5.700000e-01, 1.640000e+00,\n",
       "          4.800000e+02],\n",
       "         [1.236000e+01, 3.830000e+00, 2.380000e+00, 2.100000e+01,\n",
       "          8.800000e+01, 2.300000e+00, 9.200000e-01, 5.000000e-01,\n",
       "          1.040000e+00, 7.650000e+00, 5.600000e-01, 1.580000e+00,\n",
       "          5.200000e+02],\n",
       "         [1.296000e+01, 3.450000e+00, 2.350000e+00, 1.850000e+01,\n",
       "          1.060000e+02, 1.390000e+00, 7.000000e-01, 4.000000e-01,\n",
       "          9.400000e-01, 5.280000e+00, 6.800000e-01, 1.750000e+00,\n",
       "          6.750000e+02],\n",
       "         [1.220000e+01, 3.030000e+00, 2.320000e+00, 1.900000e+01,\n",
       "          9.600000e+01, 1.250000e+00, 4.900000e-01, 4.000000e-01,\n",
       "          7.300000e-01, 5.500000e+00, 6.600000e-01, 1.830000e+00,\n",
       "          5.100000e+02],\n",
       "         [1.277000e+01, 2.390000e+00, 2.280000e+00, 1.950000e+01,\n",
       "          8.600000e+01, 1.390000e+00, 5.100000e-01, 4.800000e-01,\n",
       "          6.400000e-01, 9.899999e+00, 5.700000e-01, 1.630000e+00,\n",
       "          4.700000e+02],\n",
       "         [1.340000e+01, 3.910000e+00, 2.480000e+00, 2.300000e+01,\n",
       "          1.020000e+02, 1.800000e+00, 7.500000e-01, 4.300000e-01,\n",
       "          1.410000e+00, 7.300000e+00, 7.000000e-01, 1.560000e+00,\n",
       "          7.500000e+02]]),\n",
       "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_cv[\"folder_1\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
